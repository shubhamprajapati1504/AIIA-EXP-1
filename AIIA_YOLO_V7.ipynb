{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O324GzQywE_6",
        "outputId": "3b9a0603-4c99-419a-aa26-087ab009d6ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1197, done.\u001b[K\n",
            "remote: Total 1197 (delta 0), reused 0 (delta 0), pack-reused 1197 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1197/1197), 74.29 MiB | 25.03 MiB/s, done.\n",
            "Resolving deltas: 100% (511/511), done.\n",
            "/content/yolov7/yolov7/yolov7/yolov7/yolov7/yolov7/yolov7\n",
            "Dataset URL: https://www.kaggle.com/datasets/niravnaik/safety-helmet-and-reflective-jacket\n",
            "License(s): apache-2.0\n",
            "Downloading safety-helmet-and-reflective-jacket.zip to ./dataset\n",
            " 97% 502M/518M [00:01<00:00, 301MB/s]\n",
            "100% 518M/518M [00:01<00:00, 397MB/s]\n",
            "âœ… data.yaml created successfully\n",
            "YOLOR ðŸš€ v0.1-128-ga207844 torch 2.2.0+cpu CPU\n",
            "\n",
            "Namespace(weights='yolov7.pt', cfg='', data='data.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=10, batch_size=4, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=True, image_weights=False, device='cpu', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=2, project='runs/train', entity=None, name='yolov7_cpu_train', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/yolov7_cpu_train', total_batch_size=4)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshubham-prajapati22\u001b[0m (\u001b[33mshubham-prajapati22-sardar-patel-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/yolov7/yolov7/yolov7/yolov7/yolov7/yolov7/yolov7/wandb/run-20250819_151152-rqbnvk1e\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov7_cpu_train\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/shubham-prajapati22-sardar-patel-institute-of-technology/YOLOR\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/shubham-prajapati22-sardar-patel-institute-of-technology/YOLOR/runs/rqbnvk1e\u001b[0m\n",
            "Downloading https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt to yolov7.pt...\n",
            "100% 72.1M/72.1M [00:00<00:00, 206MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     37695  models.yolo.Detect                      [2, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 407 layers, 37200095 parameters, 37200095 gradients, 105.1 GFLOPS\n",
            "\n",
            "Transferred 554/560 items from yolov7.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 92 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'dataset/safety-Helmet-Reflective-Jacket/train/labels' images and labels... 7350 found, 0 missing, 33 empty, 0 corrupted: 100% 7350/7350 [00:02<00:00, 2950.64it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: dataset/safety-Helmet-Reflective-Jacket/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (9.0GB): 100% 7350/7350 [00:20<00:00, 357.04it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'dataset/safety-Helmet-Reflective-Jacket/valid/labels' images and labels... 1575 found, 0 missing, 8 empty, 0 corrupted: 100% 1575/1575 [00:00<00:00, 1698.65it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: dataset/safety-Helmet-Reflective-Jacket/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (1.7GB):  89% 1407/1575 [00:18<00:08, 19.24it/s]^C\n",
            "cp: cannot stat 'runs/train/yolov7_cpu_train/weights/best.pt': No such file or directory\n",
            "âœ… best.pt saved to Google Drive (/content/drive/MyDrive/yolov7_best_cpu.pt)\n",
            "Namespace(weights=['runs/train/yolov7_cpu_train/weights/best.pt'], source='dataset/safety-Helmet-Reflective-Jacket/test/images', img_size=640, conf_thres=0.25, iou_thres=0.45, device='cpu', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='yolov7_cpu_detect', exist_ok=False, no_trace=False)\n",
            "YOLOR ðŸš€ v0.1-128-ga207844 torch 2.2.0+cpu CPU\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov7/yolov7/yolov7/yolov7/yolov7/yolov7/yolov7/detect.py\", line 196, in <module>\n",
            "    detect()\n",
            "  File \"/content/yolov7/yolov7/yolov7/yolov7/yolov7/yolov7/yolov7/detect.py\", line 34, in detect\n",
            "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/yolov7/yolov7/yolov7/yolov7/yolov7/yolov7/yolov7/models/experimental.py\", line 252, in attempt_load\n",
            "    ckpt = torch.load(w, map_location=map_location)  # load\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 998, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 445, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 426, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "                     ^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'runs/train/yolov7_cpu_train/weights/best.pt'\n"
          ]
        }
      ],
      "source": [
        "# ==========================\n",
        "# 1. Mount Google Drive\n",
        "# ==========================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ==========================\n",
        "# 2. Clone YOLOv7\n",
        "# ==========================\n",
        "!git clone https://github.com/WongKinYiu/yolov7\n",
        "%cd yolov7\n",
        "\n",
        "# ==========================\n",
        "# 3. Install dependencies (CPU only)\n",
        "# ==========================\n",
        "!pip install -q torch==2.2.0 torchvision==0.17.0 torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip install -q -r requirements.txt\n",
        "!pip install -q kaggle matplotlib\n",
        "\n",
        "# ==========================\n",
        "# 4. Setup Kaggle API\n",
        "# ==========================\n",
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"shubhampr1504\"   # ðŸ”‘ replace with your username\n",
        "os.environ['KAGGLE_KEY'] = \"10a044beb38f1a860b55bf16eb9f259b\"  # ðŸ”‘ replace with your key\n",
        "\n",
        "# ==========================\n",
        "# 5. Download dataset\n",
        "# ==========================\n",
        "!kaggle datasets download -d niravnaik/safety-helmet-and-reflective-jacket -p ./dataset\n",
        "!unzip -q ./dataset/safety-helmet-and-reflective-jacket.zip -d ./dataset/\n",
        "\n",
        "# ==========================\n",
        "# 6. Create data.yaml\n",
        "# ==========================\n",
        "data_yaml = \"\"\"\n",
        "train: dataset/safety-Helmet-Reflective-Jacket/train/images\n",
        "val: dataset/safety-Helmet-Reflective-Jacket/valid/images\n",
        "\n",
        "nc: 2\n",
        "names: ['helmet', 'jacket']\n",
        "\"\"\"\n",
        "\n",
        "with open(\"data.yaml\", \"w\") as f:\n",
        "    f.write(data_yaml)\n",
        "\n",
        "print(\"âœ… data.yaml created successfully\")\n",
        "\n",
        "# ==========================\n",
        "# 7. Train YOLOv7 on CPU\n",
        "# ==========================\n",
        "!python train.py \\\n",
        "    --workers 2 \\\n",
        "    --device cpu \\\n",
        "    --batch-size 4 \\\n",
        "    --epochs 10 \\\n",
        "    --img 640 640 \\\n",
        "    --data data.yaml \\\n",
        "    --weights yolov7.pt \\\n",
        "    --name yolov7_cpu_train \\\n",
        "    --cache\n",
        "\n",
        "# ==========================\n",
        "# 8. Copy trained model to Google Drive\n",
        "# ==========================\n",
        "!cp runs/train/yolov7_cpu_train/weights/best.pt /content/drive/MyDrive/yolov7_best_cpu.pt\n",
        "print(\"âœ… best.pt saved to Google Drive (/content/drive/MyDrive/yolov7_best_cpu.pt)\")\n",
        "\n",
        "# ==========================\n",
        "# 9. Run detection\n",
        "# ==========================\n",
        "!python detect.py \\\n",
        "    --weights runs/train/yolov7_cpu_train/weights/best.pt \\\n",
        "    --source dataset/safety-Helmet-Reflective-Jacket/test/images \\\n",
        "    --device cpu \\\n",
        "    --name yolov7_cpu_detect\n",
        "\n",
        "# ==========================\n",
        "# 10. Visualization inside Colab\n",
        "# ==========================\n",
        "import glob\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Get detected images\n",
        "detected_imgs = glob.glob(\"runs/detect/yolov7_cpu_detect/*.jpg\")\n",
        "\n",
        "# Show random 5 predictions\n",
        "random.shuffle(detected_imgs)\n",
        "for img_path in detected_imgs[:5]:\n",
        "    display(Image(filename=img_path))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "agMcehxtwFwB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}